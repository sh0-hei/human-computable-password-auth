{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人間計算可能なパスワードの機械学習による予測 関数と予測モデルを増やした上での実験\n",
    "\n",
    "### 目的\n",
    "\n",
    "村田さんの論文では、多層パーセプトロンを使った人間計算可能なパスワードの攻撃について、複雑な関数では正解率が10%程度となり難しいと結論づけている。また、村田さんの論文では簡単な関数では70%程度正解できると結論づけられている。さらに、丸野さんの論文ではLSTMを用いた予測でも同様に10%程度となり難しいと結論づけている。これに対して、複数の機械学習モデルおよび関数の組み合わせを網羅的に調べて、人間計算可能なパスワードの機械学習による予測について調べる。\n",
    "\n",
    "### 方法\n",
    "\n",
    "複数の関数、および機械学習モデルを用意し、それぞれに対してすべての組み合わせで実行させる。\n",
    "\n",
    "### 今回試す関数\n",
    "\n",
    "今回は次のような関数を試す。\n",
    "\n",
    "- 単純な足し算関数\n",
    "- 合成関数\n",
    "\n",
    "これらの関数は、村田さんの論文ではf sigmaおよびgという関数として提案されているものである。\n",
    "\n",
    "- 四重の合成関数\n",
    "\n",
    "この関数は今回新しく試す関数である。上で試した一層の合成関数と違い、四層の合成関数を用いる。\n",
    "\n",
    "### 今回試す機械学習モデル\n",
    "\n",
    "今回の実験では次のモデルを試す。\n",
    "\n",
    "- MLPモデル\n",
    "- LSTMモデル(RMSPropで最適化したもの)\n",
    "- LSTMモデル(Adamで最適化したもの)\n",
    "\n",
    "ここで、LSTMモデルは二つの最適化関数を用いて試す。これは、どちらかの最適化関数を使った場合に局所解にトラップされ学習が進まなくなるリスクを避けるためのものである。\n",
    "\n",
    "### 実験のコード\n",
    "\n",
    "今回の実験は次のコードで実行した。\n",
    "\n",
    "utils.py\n",
    "```\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Utils:\n",
    "  # グラフのプロットを行う関数\n",
    "  # keras.model.fit.historyおよび画像の保存名を引数として取る\n",
    "  @staticmethod\n",
    "  def plot_history(history :str, name :str) -> None:\n",
    "    # 学習時の学習データおよび正解データに対する正解率を表示する\n",
    "    pyplot.clf()\n",
    "    pyplot.plot(history['accuracy'])\n",
    "    pyplot.plot(history['val_accuracy'])\n",
    "    pyplot.title('model accuracy')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.ylabel('accuracy')\n",
    "    pyplot.legend(['acc', 'val_acc'], loc='lower right')\n",
    "    pyplot.savefig(\"outputs/\" + name + '_accuracy.png')\n",
    "\n",
    "    # 学習時の学習データおよび正解データに対する損失関数の値を表示する\n",
    "    pyplot.clf()\n",
    "    pyplot.plot(history['loss'])\n",
    "    pyplot.plot(history['val_loss'])\n",
    "    pyplot.title('model loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.legend(['loss', 'val_loss'], loc='lower right')\n",
    "    pyplot.savefig(\"outputs/\" + name + '_loss.png')\n",
    "    return None\n",
    "\n",
    "  @staticmethod\n",
    "  def split_to_train_and_valid(generated_passwords :pd.DataFrame) -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    generated_passwords = generated_passwords.sample(frac=1).reset_index(drop=True)\n",
    "    x = generated_passwords.drop(labels = [\"Z\"],axis = 1)\n",
    "    y = generated_passwords[\"Z\"]\n",
    "\n",
    "    # 説明変数・目的変数をそれぞれ訓練データ・テストデータに分割\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "    # データの型変換\n",
    "    #x_train = x_train.astype(float)\n",
    "    #x_test = x_test.astype(float)\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "```\n",
    "\n",
    "computable_password_generator.py\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ComputablePasswordGenerator:\n",
    "  # 人間計算可能なパスワードの流出データを模したデータを自動生成する関数群\n",
    "  # このクラスの関数を実行すると、人間計算可能なパスワードを模したデータが生成され、csvファイルとして保存される\n",
    "  # 外部のプログラムから呼び出すときは、from computable_password_generator import ComputablePasswordGenerator としてimportを行う\n",
    "\n",
    "  # この関数群の呼び出しには、int: データ数を引数として与える\n",
    "  # この関数群はpandas.DataFrameをreturnする\n",
    "  class Utils:\n",
    "    @staticmethod\n",
    "    def sgm(n :int) -> np.ndarray:\n",
    "      sgm = np.random.randint(0,10,n)\n",
    "      return sgm\n",
    "\n",
    "  class GeneratorWithMetadata:\n",
    "    def __init__(self, generator, name :str):\n",
    "      self.generator = generator\n",
    "      self.name = name\n",
    "\n",
    "  @staticmethod\n",
    "  def list_generators() -> list:\n",
    "    generators = []\n",
    "    generators.append(ComputablePasswordGenerator.GeneratorWithMetadata(ComputablePasswordGenerator.simple_pointer, \"simple_pointer\"))\n",
    "    generators.append(ComputablePasswordGenerator.GeneratorWithMetadata(ComputablePasswordGenerator.password_with_middle, \"middle\"))\n",
    "    generators.append(ComputablePasswordGenerator.GeneratorWithMetadata(ComputablePasswordGenerator.password_simple_add, \"simple_add\"))\n",
    "    return generators\n",
    "\n",
    "  @staticmethod\n",
    "  def password_simple_add(datasize :int) -> np.ndarray:\n",
    "    result = []\n",
    "    for row in range(datasize):\n",
    "      X = ComputablePasswordGenerator.Utils.sgm(14)\n",
    "      Z = (X[0] + X[1] + X[2]) % 10\n",
    "      row = np.append(X, Z)\n",
    "      result.append(row)\n",
    "    table_array = np.array(result)\n",
    "    return pd.DataFrame(table_array, columns=[\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\",\n",
    "      \"X8\", \"X9\", \"X10\", \"X11\", \"X12\",\"X13\", \"Z\"])\n",
    "\n",
    "  @staticmethod\n",
    "  def password_with_middle(datasize :int) -> np.ndarray:\n",
    "    result = []\n",
    "    for row in range(datasize):\n",
    "      X = ComputablePasswordGenerator.Utils.sgm(14)\n",
    "      mid = (X[10] + X[11]) % 10\n",
    "      Z = (X[mid] + X[12]) % 10\n",
    "      row = np.append(X, Z)\n",
    "      result.append(row)\n",
    "    table_array = np.array(result)\n",
    "    return pd.DataFrame(table_array, columns=[\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\",\n",
    "      \"X8\", \"X9\", \"X10\", \"X11\", \"X12\",\"X13\", \"Z\"])\n",
    "\n",
    "  @staticmethod\n",
    "  def simple_pointer(datasize :int) -> np.ndarray:\n",
    "    result = []\n",
    "    for row in range(datasize):\n",
    "      X = ComputablePasswordGenerator.Utils.sgm(14)\n",
    "      mid_1 = (X[10] + X[11]) % 10\n",
    "      mid_2 = (mid_1 + X[13]) % 10\n",
    "      mid_3 = (mid_2 + X[12]) % 10\n",
    "      Z = [mid_3] + X[12]\n",
    "      row = np.append(X, Z)\n",
    "      result.append(row)\n",
    "    table_array = np.array(result)\n",
    "    return pd.DataFrame(table_array, columns=[\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\",\n",
    "      \"X8\", \"X9\", \"X10\", \"X11\", \"X12\",\"X13\", \"Z\"])\n",
    "```\n",
    "\n",
    "models.py\n",
    "```\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Models:\n",
    "  class ModelWithMetadata:\n",
    "    def __init__(self, model, name :str, batch_size :int, epochs :int, required_data_size :int):\n",
    "      self.model = model\n",
    "      self.name = name\n",
    "      self.batch_size = batch_size\n",
    "      self.epochs = epochs\n",
    "      self.required_data_size = required_data_size\n",
    "\n",
    "    def resharper(self, df :pd.DataFrame) -> (np.ndarray):\n",
    "      if self.name.find(\"lstm\") != -1:\n",
    "        print(\"hoge\")\n",
    "        return df.to_numpy().reshape(df.shape[0], df.shape[1], 1)\n",
    "      return df\n",
    "\n",
    "  @staticmethod\n",
    "  def list_models() -> list:\n",
    "    models = []\n",
    "    models.append(Models.ModelWithMetadata(Models.mlp_model(), \"mlp\", 16, 512, 10000))\n",
    "    models.append(Models.ModelWithMetadata(Models.simple_lstm_with_AMSGrad(), \"simple_lstm\", 32, 1024, 50000))\n",
    "    models.append(Models.ModelWithMetadata(Models.simple_lstm_with_adam(), \"lstm_with_adam\", 32, 1024, 50000))\n",
    "    return models\n",
    "\n",
    "  # 人間計算可能なパスワードの予測に使うための機械学習モデル群\n",
    "  # これらの関数を呼び出すと、指定したSequentialモデルがreturnされる\n",
    "  @staticmethod\n",
    "  def mlp_model() -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "  @staticmethod\n",
    "  def simple_lstm_with_AMSGrad() -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape = (14, 1)))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "  @staticmethod\n",
    "  def simple_lstm_with_adam() -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape = (14, 1)))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "```\n",
    "\n",
    "main.py\n",
    "```\n",
    "from computable_password_generator import ComputablePasswordGenerator\n",
    "from utils import Utils\n",
    "from models import Models\n",
    "\n",
    "for model in Models.list_models():\n",
    "  print(\"Runnning model: {}\".format(model.name))\n",
    "  for generator in ComputablePasswordGenerator.list_generators():\n",
    "    try:\n",
    "      print(\"Testing: generator: {}, model: {}\".format(generator.name, model.name))\n",
    "      print(\"Figure name: {}\".format(generator.name + \"_\" + model.name))\n",
    "      generated_passwords = generator.generator(model.required_data_size)\n",
    "      x_train, x_test, y_train, y_test = Utils.split_to_train_and_valid(generated_passwords)\n",
    "      x_train = model.resharper(x_train)\n",
    "      print(x_train.shape)\n",
    "      x_test = model.resharper(x_test)\n",
    "      model.model.fit(x_train,y_train,batch_size=model.batch_size, epochs=model.epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "      history = model.model.history.history\n",
    "      Utils.plot_history(history, generator.name + \"_\" + model.name)\n",
    "    except Exception as e:\n",
    "      print(\"Error: generator: {}, model: {}\".format(generator.name, model.name))\n",
    "      print(e)\n",
    "      continue\n",
    "```\n",
    "\n",
    "\n",
    "### 実験結果\n",
    "\n",
    "実験の結果生成された損失関数のグラフおよび正解率のグラフは次のようになった。\n",
    "\n",
    "単純な足し算関数(simple_add)の場合\n",
    "\n",
    "MLPモデルの場合\n",
    "\n",
    "![simple_add_mlp_loss](../outputs/simple_add_mlp_loss.png)\n",
    "![simple_add_mlp_accuracy](../outputs/simple_add_mlp_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: RMSProp)の場合\n",
    "\n",
    "![simple_add_lstm_loss](../outputs/simple_add_simple_lstm_loss.png)\n",
    "![simple_add_lstm_accuracy](../outputs/simple_add_simple_lstm_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: Adam)の場合\n",
    "\n",
    "![simple_add_lstm_with_adam_loss](../outputs/simple_add_lstm_with_adam_loss.png)\n",
    "![simple_add_lstm_with_adam_accuracy](../outputs/simple_add_lstm_with_adam_accuracy.png)\n",
    "\n",
    "合成関数(middle)の場合\n",
    "\n",
    "MLPモデルの場合\n",
    "\n",
    "![middle_mlp_loss](../outputs/middle_mlp_loss.png)\n",
    "![middle_mlp_accuracy](../outputs/middle_mlp_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: RMSProp)の場合\n",
    "\n",
    "![middle_lstm_loss](../outputs/middle_simple_lstm_loss.png)\n",
    "![middle_lstm_accuracy](../outputs/middle_simple_lstm_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: Adam)の場合\n",
    "\n",
    "![middle_lstm_with_adam_loss](../outputs/middle_lstm_with_adam_loss.png)\n",
    "![middle_lstm_with_adam_accuracy](../outputs/middle_lstm_with_adam_accuracy.png)\n",
    "\n",
    "四重合成関数(pointer)の場合\n",
    "\n",
    "MLPモデルの場合\n",
    "\n",
    "![simple_pointer_mlp_loss](../outputs/simple_pointer_mlp_loss.png)\n",
    "![simple_pointer_mlp_accuracy](../outputs/simple_pointer_mlp_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: RMSProp)の場合\n",
    "\n",
    "![simple_pointer_lstm_loss](../outputs/simple_pointer_simple_lstm_loss.png)\n",
    "![simple_pointer_lstm_accuracy](../outputs/simple_pointer_simple_lstm_accuracy.png)\n",
    "\n",
    "LSTMモデル(最適化関数: Adam)の場合\n",
    "\n",
    "![simple_pointer_lstm_with_adam_loss](../outputs/simple_pointer_lstm_with_adam_loss.png)\n",
    "![simple_pointer_lstm_with_adam_accuracy](../outputs/simple_pointer_lstm_with_adam_accuracy.png)\n",
    "\n",
    "### 考察\n",
    "\n",
    "これまでの論文で検証されていた組み合わせについては、これまでの論文とほぼ同じ結果になったと言える。ここで、同じLSTMモデルでも最初の足し算関数については最適化関数によってグラフの形が大きく変わっていることがわかる。これは、RMSPropが学習率を適宜調整する仕組みであることに対して、AdamはRMSPropの結果にMomentumの結果を加えた分の学習をするという差があることによると考えられる。RMSPropでは最適化がうまくいったが、Adamでは途中で学習率が大きくなりすぎた結果局所解にトラップされた可能性が高いと考えられる。また、中間層が一つだけの関数と比較して、複数の合成関数を活用する関数の場合ではLSTMモデルを活用した場合でも正解率が10%程度となっており、従来の一層だけの合成関数と比較して機械学習による予測が難しくなったといえる。\n",
    "\n",
    "### 今後の課題\n",
    "\n",
    "機械学習での予測を難しくするための手法として、複数の合成関数を活用する手法があることがわかった。一方で、人間にとっては扱いづらいパスワードとなることが予想される。そのため、どこまで安全性を担保する必要が現実的にあるのかを調べるために、従来の関数に対して様々なモデルで予測可能性の評価を行う必要がある。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
